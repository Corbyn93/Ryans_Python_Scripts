{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import matplotlib.pyplot as plot\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "from matplotlib.collections import PatchCollection\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import csv \n",
    "import numpy as np \n",
    "import skimage.feature as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_name):\n",
    "    with open(file_name, 'r') as array3D:\n",
    "        content = array3D.read()\n",
    "    \n",
    "    # Sort data into two variables , one with the image data (scan_array)\n",
    "    # and another with the meta data for the image. \n",
    "    scan_array = []\n",
    "    meta_data = []\n",
    "\n",
    "    lines = content.splitlines()#[6:]\n",
    "    for line in lines:\n",
    "        columns = line.split('\\t')\n",
    "        if len(columns) < 20:\n",
    "            meta_data.append(columns)\n",
    "            continue \n",
    "        scan_array.append(columns[0:len(columns)-1]) \n",
    "\n",
    "    # convert the scan_array list into a float array. \n",
    "    image_array = np.array(scan_array, dtype = np.float)\n",
    "    \n",
    "    max_fluorescence = np.max(image_array)\n",
    "    \n",
    "    return(image_array, meta_data, max_fluorescence)\n",
    "    #background = np.mean(image_data)\n",
    "    #print(background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_scales(meta_data):\n",
    "    # Extract the XYZ scaling information from the meta_data list. \n",
    "    xy = meta_data[10]\n",
    "    XYscaling = np.array(xy[0:len(xy)-1], dtype = np.float)\n",
    "    #find the maximum scan length\n",
    "    scan_maxima = [XYscaling[2]-XYscaling[1], \n",
    "                   XYscaling[5]- XYscaling[4]]\n",
    "    \n",
    "    voxel_size = np.empty([len(scan_maxima)])\n",
    "    #find the size of each voxel/pixel\n",
    "    for i in range(len(scan_maxima)):\n",
    "        voxel_size[i] = scan_maxima[i]/int(XYscaling[i*3+3]) \n",
    "\n",
    "    # Create the pixle arrays for both the x and y range.\n",
    "    x_scan = np.linspace(0, scan_maxima[0], int(XYscaling[3]))\n",
    "    y_scan = np.linspace(0, scan_maxima[1], int(XYscaling[6]))\n",
    "    \n",
    "    return(x_scan, y_scan, voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_d_meshgrid(x_scan, y_scan, image_data):\n",
    "    # create a mesh grid fo the heatmap\n",
    "    X, Y = np.meshgrid(x_scan, y_scan)\n",
    "    # Put all the data into a pandas data frame. \n",
    "    data_array = pd.DataFrame({'x':X.ravel(), 'y':Y.ravel(), 'Counts':image_data.ravel()})\n",
    "    #the data_array needs to be pivoted to display properly in the heatmap.\n",
    "    image_frame = data_array.pivot('y', 'x','Counts')\n",
    "    return(image_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tick_labels(scan_data):\n",
    "    # Get the values for tick marks incase they are needed for plotting. \n",
    "    ticks = [] \n",
    "    indicies = []\n",
    "    for i in range(len(scan_data)):\n",
    "        if i/20 == np.floor(i/20):\n",
    "            ticks.append(scan_data[i])\n",
    "            indicies.append(i)\n",
    "    \n",
    "    return(ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scalebar(x_scan, voxel_size, ax):\n",
    "    # defines the length of the scale bar and its caption.\n",
    "    scale_bar_pixel_length = 0.1* len(x_scan)\n",
    "    scale_bar_si_length = round(scale_bar_pixel_length*voxel_size, 1)\n",
    "    \n",
    "    #Generate scale bar\n",
    "    bar = AnchoredSizeBar(ax.transData, scale_bar_pixel_length, \n",
    "                          str(scale_bar_si_length) + r'$\\mu$m', \n",
    "                          4, size_vertical = 1, pad = 0.25)\n",
    "   # Add scalebar to image\n",
    "    ax.add_artist(bar)\n",
    "    \n",
    "    return(int(scale_bar_pixel_length), scale_bar_si_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_NDs(image_frame, min_dis, num_NDs):\n",
    "    # Uses the skimage package to locate the local maxima of an image. \n",
    "    nd_locations = si.peak_local_max(image_frame, min_distance = min_dis, exclude_border = True, num_peaks = num_NDs)\n",
    "\n",
    "    return(nd_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(image_frame, xticks, yticks, max_fluorescence):\n",
    "    ## This section produces a seaborn heatmap with no x and y labels or tick marks.\n",
    "\n",
    "    #generate a subpolt.\n",
    "    fig, ax = plot.subplots()\n",
    "    # change the plot text sizes. \n",
    "    sns.set(rc={'figure.figsize':(12,8)}, font_scale = 1.5)\n",
    "    # generate the heatmap \n",
    "    \n",
    "    #Code for making a cube-helix colour map\n",
    "    #cmap = sns.cubehelix_palette(start = 0.5, rot = .3, reverse = True, dark=0.3, light=1, as_cmap=True)\n",
    "    cmap = 'viridis'\n",
    "    \n",
    "    heat_map = sns.heatmap(image_frame, vmin =0 , vmax = 0.90*max_fluorescence,\n",
    "                           cbar_kws = {'label':'\\n Counts (per int time)'},\n",
    "                           xticklabels = 20, yticklabels = 20, cmap = cmap)\n",
    "    # set the tick marks for the heat map.\n",
    "    ax.set_yticklabels(yticks, rotation = 0)\n",
    "    ax.set_xticklabels(xticks, rotation = 0)\n",
    "    # set the x and y labels. \n",
    "    ax.set_ylabel('y ' + r'($\\mu$m)')\n",
    "    ax.set_xlabel('x ' + r'($\\mu$m)')\n",
    "\n",
    "    return(fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI_comparison(image_array, image_array_2, ND_locs):\n",
    "    # Here we compare the different intensities of the \n",
    "    # NDs from two different ND maps. \n",
    "    fluor_drop = []\n",
    "    for i in range(len(ND_locs)):\n",
    "        y, x = ND_locs[i]\n",
    "        fluor_drop.append(image_array_2[x,y]/image_array[x,y])\n",
    "        \n",
    "    return(fluor_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_useful_NDs(ROI_contrast, limit):\n",
    "    # identify NDs with a contrast above a limit\n",
    "    ODMR_NDs = []\n",
    "    for i in range(len(ROI_contrast)):\n",
    "        if (1-ROI_contrast[i]) > limit:\n",
    "            ODMR_NDs.append(i)\n",
    "    return(ODMR_NDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roi(nd_locs, ax, color, radius):\n",
    "    ## I have grabbed/ammended this function from: \n",
    "    # https://stackoverflow.com/questions/51672327/skimage-peak-local-max-finds-multiple-spots-in-close-proximity-due-to-image-impu\n",
    "    # I am sure that this isn't an issue for copyright/IP or anything, but better to be safe. \n",
    "\n",
    "    # This function plots all of the regions of interest onto the heatmap. \n",
    "    patches = []\n",
    "    a = 1\n",
    "    for nd in nd_locs:\n",
    "        y, x = nd\n",
    "        c = plot.Circle((x, y), radius)\n",
    "        ax.annotate('ND ' + str(a), xy = [x-2, y + 10], color = color)\n",
    "        patches.append(c)\n",
    "        a += 1\n",
    "        \n",
    "    ax.add_collection(PatchCollection(patches, facecolors = \"None\", edgecolors = color, alpha = 0.5, linewidths = 3))\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_background(image_array):\n",
    "    # Find the background fluorescence value.\n",
    "    background = np.mean(image_array)\n",
    "    image_array_zero = image_array - background\n",
    "    return(image_array_zero, background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_to_background(image_array, background):\n",
    "    #Normalise the 2D map to the fluroescent background. \n",
    "    normalised_image = image_array/background\n",
    "    return(normalised_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e3eba8aa991b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mimage_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwo_d_meshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_scan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Get labels for tick marks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5c1bb4b1e07f>\u001b[0m in \u001b[0;36mtwo_d_meshgrid\u001b[1;34m(x_scan, y_scan, image_data)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_scan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_scan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Put all the data into a pandas data frame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mdata_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Counts'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m#the data_array needs to be pivoted to display properly in the heatmap.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mimage_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Counts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Ryan\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    433\u001b[0m             )\n\u001b[0;32m    434\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Ryan\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         ]\n\u001b[1;32m--> 254\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Ryan\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\Ryan\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arrays must all be same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "# Get the location of the file of interest in the directory. \n",
    "folder_name = 'I:\\\\Science\\\\Physics-Nanobiophotonics\\\\Group\\\\User Data\\\\ODMR\\\\ODMR and imaging\\\\20200821\\\\'\n",
    "date = '20200821'\n",
    "file_name = folder_name + date + '_01.dat'\n",
    "\n",
    "# Sort the image data and the meta data into different variables, extract the max fluorescence value. \n",
    "image_array, meta_data, max_fluorescence = get_data(file_name)\n",
    "# Generate arrays describing the 2D scans used to create the image. \n",
    "x_scan, y_scan, voxel_size = xy_scales(meta_data)\n",
    "# Store scan and image data into a pandas data frame. \n",
    "\n",
    "# find and subtract the backgrounf fluorescence from the image\n",
    "image_arr, background = subtract_background(image_array)\n",
    "\n",
    "\n",
    "image_frame = two_d_meshgrid(x_scan, y_scan, image_arr)\n",
    "\n",
    "# Get labels for tick marks.\n",
    "x_ticks = get_tick_labels(x_scan)\n",
    "y_ticks = get_tick_labels(y_scan)\n",
    "\n",
    "#Generate/call second image, subtract background and create second image data frame.\n",
    "#image_array_2a = image_array*0.93\n",
    "#image_array_2 = np.int_(image_array_2a)\n",
    "#image_arr_2, background_2 = subtract_background(image_array_2)\n",
    "#image_frame_2 = two_d_meshgrid(x_scan, y_scan, image_array_2)\n",
    "\n",
    "# Locate the nanodiamonds within an image. \n",
    "#find_NDs(image_array, Minimum distance to check for another maxima, number of NDs to search for.)\n",
    "nd_locs_im_1 = find_NDs(image_arr, 3, 3)\n",
    "\n",
    "# Find the change in contrast between the first and second image.\n",
    "#roi_contrast = ROI_comparison(image_arr,image_arr_2, nd_locs_im_1)\n",
    "#print(ROI_drops)\n",
    "\n",
    "#Plot the heatmap\n",
    "fig, ax = plot_heatmap(image_frame, x_ticks, y_ticks, max_fluorescence)\n",
    "# Generate and plot the scale bar.\n",
    "scale_bar_pix, scale_bar_si = get_scalebar(x_scan, voxel_size[0], ax)\n",
    "\n",
    "# Identify the NDs with a fluorescence change of <7%\n",
    "#useful_NDs = find_useful_NDs(roi_contrast, 0.07)\n",
    "\n",
    "#Select the nanodiamonds in plot with a contrast above the limit for experiment\n",
    "plot_roi(nd_locs_im_1, ax, 'yellow', radius = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('C:\\\\Users\\\\Ryan\\\\Desktop\\\\' + date + '_NDs_map1' + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
